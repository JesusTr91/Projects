---
output:
  pdf_document: default
  html_document: default
---
# Us College Majors Cluster Analysis

## Introduction

Choosing a major is a difficult decision almost everyone  has to make. This milestone will influence every studentâ€™s career trajectory for good or bad.

Young people are encouraged to weight several factors before making a final decision such as:

* Employment rates in the field
* Advanced degree opportunities
* Salary expectations
* Overall program cost

## Objetive

Since its a major life decision, we want to informe young people about the advantages or disadvantages they may encounter when selecting an specific major. Hence, we will compare the recommendations from three different methods for determining the optimal number of clusters, apply a k-means clustering analysis, and visualize the results.

## Data

We will use a year-long survey of 1.2 million people with only a bachelor's degree by PayScale.Inc that can be found [here](http://online.wsj.com/public/resources/documents/info-Degrees_that_Pay_you_Back-sort.html?mod=article_inline).

```{r warning=FALSE, message=FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(readr)
library(cluster)
library(factoextra)

majors <- read.csv('Us_college.csv')
col_names=c('College.Major', 'Starting.Median.Salary','Mid.Career.Median.Salary',
            'Career.Percent.Growth', 'Percentile.10','Percentile.25',
            'Percentile.75','Percentile.90')
names(majors) <- col_names
print(head(majors))
```

### Data Cleaning

```{r}
majors_clean <- majors %>% 
    mutate_at(vars(Starting.Median.Salary:Percentile.90), 
              function(x) as.numeric(gsub("[\\$,]","",x))) %>%
    mutate(Career.Percent.Growth = Career.Percent.Growth/100)
```

## Clustering Analysis

First step, we have to determine the number of clusters we should model. There are several methods to get to an aproach, since one its not enough for the task. Hence we will use 3 techniques to optimize the number of clusters:

* Gap static method
* Silhouette method
* Elbow method

```{r}
data <- majors_clean %>%
    select(Starting.Median.Salary, Mid.Career.Median.Salary, 
           Percentile.10, Percentile.90) %>% scale()
```

### Gap static method

Our first method compares the total variation within clusters for different values of k to the null hypothesis, making this to maximize the gap. This hypothesis refers to a uniformly distributed simulated reference dataset with no observable clusters, generated by aligning with the principle components of our original dataset.

```{r fig.align='center'}
gap_stat <- clusGap(data, FUN = kmeans, nstart = 25, K.max = 10, B = 50)

gap_static <- fviz_gap_stat(gap_stat)
gap_static
```

In the above visualization we see how much the variance is explained by k clusters in our dataset, making the ideal value 3 for our clusters.

### Silhouette Method

This method evaluates the clusters quality by how well each point fits within a cluster, maximizing average silhouette width.

```{r fig.align='center'}
silhouette <- fviz_nbclust(data, kmeans, method = "silhouette")
silhouette
```

Finally, the elbow method, which is the most common to use for this type of situations. This method plots the percent variance against the number of clusters. 

```{r fig.align='center'}
elbow <- fviz_nbclust(data, kmeans, method = "wss")
elbow
```

As you can see there is a break point at the value 3, making the curve to bend like an elbow. This indicates the optimal point at which adding more clusters will no longer explain a significant amount of the variance.

## K-means Algotithm

Once we have our results (2, 3 and 3) we can be sure that working with 3 clusters will be the best for our model.

```{r}
set.seed(354)
num <- 3
k_means <- kmeans(data, num, iter.max = 15, nstart = 25)

majors_labld <- majors_clean %>%
    mutate(clusters = k_means$cluster)
```

Accordingly to this, lets start by getting a view to how each cluster compares in terms of starting vs mid career salaries.

```{r}
career <- ggplot(majors_labld, 
                 aes(x=Starting.Median.Salary,y=Mid.Career.Median.Salary, 
                     color=factor(clusters))) + 
      geom_point(alpha=0.75,size=6) + 
      scale_color_manual(name="Clusters",values=c("#2A9D8F","#E9C46A", "#E76F51")) + 
      ggtitle('Clusters by Starting vs Mid Career Median Salaries') + 
      scale_x_continuous(labels = scales::dollar) + 
      scale_y_continuous(labels = scales::dollar) + 
      labs(x='Starting Median Salary', y='Mid Career Median Salary')
career
```

As shown in the visualization the data follows a linear trend meaning that the higher your starting salary is, the higher your mid career salary will be. The clusters provide a level of delineation that also supports this.

Furthermore we also can see two outliners from cluster 1 and 3 that may be explained if we go deeper into our analysis and get insights of the career salaries percentiles. 

```{r}
percentiles <- majors_labld %>%
    select(College.Major, Percentile.10, Percentile.25, 
           Mid.Career.Median.Salary, Percentile.75, 
           Percentile.90, clusters) %>%
    gather(key=percentile, value=salary, -c(College.Major, clusters)) %>%
    mutate(percentile=factor(percentile,levels=c('Percentile.10','Percentile.25',
            'Mid.Career.Median.Salary','Percentile.75','Percentile.90')))
```

## Cluster 1: Applied Sciences Pathway

It seems this cluster is characterized by job stability and sets in the middle of the road in our dataset starting off not too low and not too high in the lowest percentile. It also represents the majors with the greatest difference between the lowest and highest percentiles.

```{r fig.align='center'}
cluster_1 <-  ggplot(percentiles[percentiles$clusters==1,], 
                    aes(x=percentile,y=salary, 
                    group=College.Major, color=College.Major, order=salary)) +
                    geom_point() +
                    geom_line() + 
                    theme(axis.text.x = element_text(size=7, angle=25)) +
                    ggtitle('Cluster 1: Applied Sciences Pathway') +
                    labs(x='Percentile', y='Salary') 
cluster_1
```

## Cluster 2: Engineering and math pathway

If you are good at math and want financial security you should consider one of this mayors. These engineering majors represent the highest growth potential in the 90th percentile, as well as the best security in the 10th percentile rankings. We see one of the outliers, now identifiable as Physician Assistant lagging in the highest percentiles.

```{r}
cluster_2 <- ggplot(percentiles[percentiles$clusters==2,], 
    aes(x=percentile,y=salary, 
    group=College.Major, color=College.Major)) +
    geom_point() +
    geom_line() +
    ggtitle('Cluster 2: Engineering and Math Pathway') +
    theme(axis.text.x = element_text(size=7, angle=25)) +
    labs(x='Percentile', y='Salary')
cluster_2
```

## Cluster 1: Art and Human Sciences Pathway

Not all is science and math, there are also good majors with a lot of opportunities. If you are passionate about art or have the hearth to help others these are good options. However the majors surrounding this cluster represent the lowest percentiles with limited growth opportunity.

Music major is the riskiest with the lowest 10th percentile salary, but Drama has the highest growth potential in the 90th percentile for this cluster. Nursing is the outlier culprit of this cluster, with a higher safety net in the lowest percentile to the median.

```{r}
cluster_3 <- ggplot(percentiles[percentiles$clusters==3,], 
    aes(x=percentile,y=salary, 
    group=College.Major, color=College.Major)) +
    geom_point() +
    geom_line() +
    ggtitle('Cluster 3: Art and Human Sciences Pathway') +
    theme(axis.text.x = element_text(size=7, angle=25)) +
    labs(x='Percentile', y='Salary')

cluster_3
```

## Conclusions and recommendations

Dealing with unsupervised data always requires skill and some creativity. It is recommended the use of not just one method to look after the ideal number of clusters but to use more to be certain and get a good model.

Yes, it is important to focus on high starting career salaries when choosing a major and to consider the growth potential. However, keep in mind that whether a major falls to the sciences, engineering or arts and human sciences cluster, one's financial destiny is influenced by numerous other factors including the school attended, passion or talent for the subject.

If you are curious about the factors mentioned above, a similar analysis to evaluate them can be conducted on the additional data provided by the Wall Street Journal article, comparing salary potential by type and region of college attended.

Regardless of the salaries, job opportunities and other factors, I want to remind you the most important thing: Follow your passions!

```{r results='asis', echo=FALSE, warning=FALSE}
library(knitr)
col_names=c('College <br> Major', 'Start Median Salary','Mid Median Salary','Percent Growth', 'Percntl 10','Percntl 25','Percntl 75','Perctnl 90', 'Cluster')
names(majors_labld) <- col_names
kable(arrange(majors_labld,desc('Percent Growth')), caption='Top College Majors Sorted by Career Percent Growth')
```