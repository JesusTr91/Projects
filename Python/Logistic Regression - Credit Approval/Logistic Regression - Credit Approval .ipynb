{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Credit Approval \n",
    "\n",
    "## Introduction\n",
    "\n",
    "One of the biggest problems banks used to face was the large number of applications for credit cards. People could be rejected by having low income level or high loan balances and analyzing these applications one by one was a headache. Fortunately, today we have technology and this tasks can be automated with the power of machine learning.\n",
    "\n",
    "## Objetive\n",
    "\n",
    "Firstly we want our data in good shape so our model to make good predictions, consequentely we are going to preprocess the dataset by cleaning it so we can perform the exploratory data analysis. The goal is to build a machine learning model that can predict if an individual's application for a credit card will be accepted or not.\n",
    "\n",
    "## Data\n",
    "\n",
    "We will use the \"Credit Approval Data Set\" from the University of California, Irvine Machine Learning Repository, [here](http://archive.ics.uci.edu/ml/datasets/credit+approval).\n",
    "\n",
    "The file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values. since this data is confidential, the contributor of the dataset has anonymized the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCstomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>Approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender    Age   Debt Married BankCstomer EducationLevel Ethnicity  \\\n",
       "0      b  30.83  0.000       u           g              w         v   \n",
       "1      a  58.67  4.460       u           g              q         h   \n",
       "2      a  24.50  0.500       u           g              q         h   \n",
       "3      b  27.83  1.540       u           g              w         v   \n",
       "4      b  20.17  5.625       u           g              w         v   \n",
       "\n",
       "   YearsEmployed PriorDefault Employed  CreditScore DriversLicense Citizen  \\\n",
       "0           1.25            t        t            1              f       g   \n",
       "1           3.04            t        t            6              f       g   \n",
       "2           1.50            t        f            0              f       g   \n",
       "3           3.75            t        t            5              t       g   \n",
       "4           1.71            t        f            0              f       s   \n",
       "\n",
       "  ZipCode  Income Approved  \n",
       "0   00202       0        +  \n",
       "1   00043     560        +  \n",
       "2   00280     824        +  \n",
       "3   00100       3        +  \n",
       "4   00120       0        +  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"credit.data\", header = None)\n",
    "df.columns=['Gender', 'Age', 'Debt', 'Married', 'BankCstomer', 'EducationLevel', 'Ethnicity', \n",
    "           'YearsEmployed', 'PriorDefault', 'Employed', 'CreditScore', 'DriversLicense', 'Citizen', 'ZipCode', \n",
    "           'Income', 'Approved']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>1017.385507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>5210.102598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>395.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           7          10             14\n",
       "count  690.000000  690.000000  690.00000     690.000000\n",
       "mean     4.758725    2.223406    2.40000    1017.385507\n",
       "std      4.978163    3.346513    4.86294    5210.102598\n",
       "min      0.000000    0.000000    0.00000       0.000000\n",
       "25%      1.000000    0.165000    0.00000       0.000000\n",
       "50%      2.750000    1.000000    0.00000       5.000000\n",
       "75%      7.207500    2.625000    3.00000     395.500000\n",
       "max     28.000000   28.500000   67.00000  100000.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "The data has some issues that can affect the performance of our model if they go unfixed:\n",
    "\n",
    "It contains both numeric and non-numeric data and also values from several ranges. Some features have a value range of 0 - 28, some have a range of 2 - 67, and some have a range of 1017 - 100000. The dataset also has missing values labeled with '?', which can be seen in the last cell's output.\n",
    "\n",
    "So, we are going to replace temporarely this '?' characters with nans and impute the missing values with a strategy called mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender            12\n",
       "Age               12\n",
       "Debt               0\n",
       "Married            6\n",
       "BankCstomer        6\n",
       "EducationLevel     9\n",
       "Ethnicity          9\n",
       "YearsEmployed      0\n",
       "PriorDefault       0\n",
       "Employed           0\n",
       "CreditScore        0\n",
       "DriversLicense     0\n",
       "Citizen            0\n",
       "ZipCode           13\n",
       "Income             0\n",
       "Approved           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(\"?\", np.NaN)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing its easy for numeric columns, however for non numeric we do something different. Similarly, we are going to inpute the missing values with the most frequent values as present in the respective columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender            0\n",
       "Age               0\n",
       "Debt              0\n",
       "Married           0\n",
       "BankCstomer       0\n",
       "EducationLevel    0\n",
       "Ethnicity         0\n",
       "YearsEmployed     0\n",
       "PriorDefault      0\n",
       "Employed          0\n",
       "CreditScore       0\n",
       "DriversLicense    0\n",
       "Citizen           0\n",
       "ZipCode           0\n",
       "Income            0\n",
       "Approved          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df:\n",
    "    if df[col].dtypes == 'object':\n",
    "        df = df.fillna(df[col].value_counts().index[0])\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting and Preprocessing\n",
    "\n",
    "Before we proceed towards building our model, we still have some work to be done. We need to convert non-numeric columns into numeric, scale the feature values to a uniform range and split the data into train and test sets.\n",
    "\n",
    "We do his because many machine learning algorithms require data to be strickly numeric, and also for faster computation. This technique is called label encoding.\n",
    "\n",
    "Finally, we are going to scale our data from 0 to 1. For example, The credit score of a person is their creditworthiness based on their credit history. The higher this number, the more financially trustworthy a person is considered to be. So, a CreditScore of 1 is the highest since we're rescaling all the values to the range from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in df:\n",
    "    if df[col].dtype=='object':\n",
    "        df[col]=le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      68\n",
       "1      11\n",
       "2      96\n",
       "3      31\n",
       "4      37\n",
       "       ..\n",
       "685    90\n",
       "686    67\n",
       "687    67\n",
       "688    96\n",
       "689     0\n",
       "Name: ZipCode, Length: 690, dtype: int32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['DriversLicense', 'ZipCode'], axis=1)\n",
    "df = df.values\n",
    "\n",
    "X,y = df[:,0:13] , df[:,13]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Fitting\n",
    "\n",
    "Basically, credit prediction is a classification task. According to University of California, this dataset contains more instances that correspond to denial status than instances corresponding to approved ones. Out of 690 instances, there are 383 (55.5%) applications that got denied and 307 (44.5%) applications that got approved. Our model would be succesful if it is able to accurately predict the status of the applications with respect to these statistics.\n",
    "\n",
    "Subsequently, we want to evaluate the model on the test set with respect to classification accuracy. In the case of predicting credit approvals, it is equally important to see if our  model is able to predict the approval status of the applications as denied that originally got denied. If our model is not performing well in this aspect, then it might end up approving the application that should have been approved. The confusion matrix helps us to view our model's performance from these aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(rescaledX_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  0.8377192982456141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[92, 11],\n",
       "       [26, 99]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(rescaledX_test)\n",
    "print(\"Accuracy of logistic regression classifier: \", model.score(rescaledX_test, y_test))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has an accuray of 83%, which its good. Lets see if we can make it better by performing a grid search of the model parameters. There are different parameters, but for this time we are going to look after tol and max_iter and see whci values work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = [0.01, 0.001, 0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "param_grid = dict(tol = tol, max_iter = max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.850725 using {'max_iter': 100, 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "grid_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "grid_result = grid_model.fit(rescaledX, y)\n",
    "\n",
    "best_score, best_params = grid_result.best_score_, grid_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations\n",
    "\n",
    "Thanks to the technology we have today, we now can automate tedious and time consumming tasks. Specifically, with this project we solve one of the problems banks most used to face: review a large number of applications for credits.\n",
    "\n",
    "By building this credit predictor, we tackled some of the most widely-known preprocessing steps such as scaling, label encoding, and missing value imputation. We built a logistic regression model that can predict if a person's application for a credit would get approved or not given some information about that person.\n",
    "\n",
    "An interesting question you can ask yourself is: Which are the features that affect the credit approval decision process? Are these variables correlated with each other? For this project we rely on our intuition that they indeed are correlated, but get to know wich ones are the most importants would be interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
